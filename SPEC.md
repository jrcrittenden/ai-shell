# AIâ€‘Shell **Coding Agent** Specification Â â€”Â v0.3Â (2025â€‘06â€‘15)

> **Mission**Â â€” Guide an autonomous or semiâ€‘autonomous LLM coder (Cline, Claudeâ€‘3, GPTâ€‘Engineer, etc.) in extending and hardening the **aiâ€‘shell** project while staying within predefined safety and quality constraints.
> 
> _This spec describes the engineering roadmap, coding standards, and project context. Implementationâ€‘level toolâ€‘call schemas and runtime interaction rules are documented elsewhere._

---

## 0Â Â Project Overview Â ğŸ“œ

`aiâ€‘shell` is a **terminalâ€‘native productivity tool** that fuses three interchangeable interaction modes:

1. **LLM Chat**Â â€” direct conversation with a centrally hosted LLM (e.g., OpenAIâ€‘shape endpoint).
2. **Local Operator Chat**Â â€” conversation with a selfâ€‘hosted agent mesh exposing an SSE `/chat` endpoint.
3. **Standard Shell**Â â€” an interactive commandâ€‘line session tethered to the user's preferred shell (bash, zsh, fish, PowerShell, etc.).

Core properties:

- **Humanâ€‘inâ€‘theâ€‘Loop Safety**Â â€” AI suggestions are surfaced for approval before any command runs.
- **Backend Agnostic**Â â€” plugâ€‘in drivers for OpenAIâ€‘compatible APIs and Local Operator out of the box.
- **Portable**Â â€” single static Go binary for macOS, Linux, Windows (WSL fallback).
- **Extensible**Â â€” upcoming plugin SPI for Git, Docker, AWSâ€‘CLI, k8s, etc.

Current MVP has basic UI, generic shell execution, and backend abstraction but lacks streaming, approval UI, config loader, and plugin architecture.

---

## 1Â Â Operating Environment

|Item|Spec|
|---|---|
|**Go**|1.22.x|
|**Module path**|`github.com/jrcrittenden/ai-shell`|
|**Key Deps**|Bubble Tea v0.25, Bubbles v0.15, Lipgloss v0.9, goâ€‘openai v1.20|
|**OS targets**|Darwin/amd64+arm64, Linux/amd64+arm64, Windows/amd64 (WSL)|
|**CI**|GitHub Actions + Makefile|

---

## 2Â Â Milestones & Acceptance Tests Â ğŸ

|   |   |   |
|---|---|---|
|Phase|Description|Exit Criteria|
|**M0**|Compileâ€‘clean scaffold|`go vet ./... && go test ./...` = 0|
|**M1**|**Viewport streaming** via `viewport.Append()`|Demo shows realâ€‘time token flow|
|**M2**|**Approval modal** (dialog component)|Y/N/E keys trigger correct events|
|**M3**|**LLM streaming** (OpenAI chunks â†’ viewport)|`TestStreamChunks` passes|
|**M4**|**Config loader** (`~/.config/ai-shell/config.yml` + env overrides)|`TestLoadConfig` passes|
|**M5**|**Unit coverage â‰¥ 80 %**|`go test -cover` â‰¥ 0.80|
|**M6**|**Plugin architecture draft**|SPI doc merged + dummy plugin loads|
|**M7**|**Dockerised release pipeline**|`make release` publishes multiâ€‘arch image + GitHub tag|

_New milestones must be proposed and approved before work begins._

---

## 3Â Â Canonical Repository Layout Â ğŸ—‚ï¸

```
aiâ€‘shell/
â”œâ”€â”€ cmd/                 # future subâ€‘commands (daemon, plugin host, etc.)
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ tui/             # Bubble Tea widgets (dialogs, spinners, keymaps)
â”‚   â”œâ”€â”€ exec/            # PTY/sandbox helpers
â”‚   â”œâ”€â”€ config/          # Config load + validation
â”‚   â””â”€â”€ plugins/         # SPI + plugin loader (planned M6)
â”œâ”€â”€ llm/                 # backend abstraction layer
â”œâ”€â”€ model.go             # core TUI model (update/view)
â”œâ”€â”€ main.go              # CLI entry point
â”œâ”€â”€ go.mod / go.sum
â””â”€â”€ README.md
```

Structural changes require a migration note and README update.

---

## 4Â Â Coding Standards Â ğŸ› ï¸

1. **Formatting** â€” `go fmt ./...` & `goimports` must leave zero diff.
2. **Contexts** â€” All blocking ops accept `ctx context.Context`.
3. **Logging** â€” `log/slog` (`Info` default); avoid `fmt.Println`.
4. **Error wrapping** â€” `%w` via `fmt.Errorf` / `errors.Join`; no silent ignores.
5. **Tests** â€” Parallel by default; use `t.Setenv` and temp dirs.
6. **Commits** â€” Conventional Commits (`feat:`, `fix:`, `refactor:`, `docs:`).=

---

## 5Â Â CI / CD Pipeline Â âš™ï¸

- `make vet` Â Â Â Â Â Â Â Â â€” `go vet ./...`
- `make test` Â Â Â Â Â Â Â Â â€” `go test ./... -cover`
- `make release` Â Â Â Â â€” builds `ai-shell` for darwin/linux/windows amd64+arm64, creates GitHub release, pushes Docker image.

Github Actions skeleton provided in repository (`.github/workflows/ci.yml`).

---

## 6Â Â Security & Resource Rules Â ğŸ›¡ï¸

- No outbound network calls in tests; mock via `httptest`.
- Max CPU per `go test` package 2 s (`-timeout=2s`).
- Shell commands executed through sandboxed PTY helper.
- Writes limited to repo path, `$HOME/.cache/ai-shell`, or `/tmp`.
- `go:embed` limited to â‰¤ 100 kB per file.

---

## 7Â Â Glossary Â ğŸ“–

|   |   |
|---|---|
|Term|Meaning|
|_Local Operator_|Agent framework exposing `/chat` SSE endpoint.|
|_LLM Driver_|Code that implements `llm.Client` interface.|
|_SPI_|Service Provider Interface for plugin|

# Bubble Tea Best Practices

## 1. Keep the Event Loop Fast

The event loop processes messages in this order:
1. Message received from channel
2. Message sent to `Update()` method
3. Command returned and sent to channel
4. `View()` method invoked
5. Loop repeats

To maintain responsiveness:
- Keep `Update()` and `View()` methods fast
- Offload expensive operations to `tea.Cmd`
- Avoid blocking operations in the main event loop

Example of proper async handling:
```go
// Don't do this:
time.Sleep(time.Minute)

// Do this instead:
return m, func() tea.Msg {
    time.Sleep(time.Minute)
    return someMsg
}
```

## 2. Debugging with Message Dumping

For debugging, implement message dumping to a file:
- Use `spew` to pretty print messages
- Enable via DEBUG environment variable
- Tail the log file in another terminal

This helps track:
- Window resize events
- Key presses
- Custom messages
- Message ordering

## 3. Live Reload Development

Implement live reload for faster development:
- Watch for code changes
- Rebuild automatically
- Restart the program
- Consider using tools like `air` or `watchexec`

## 4. Model Receiver Methods

Choose receiver types carefully:
- Value receivers for immutable state
- Pointer receivers for mutable state
- Be consistent with receiver types
- Avoid race conditions in concurrent operations

## 5. Layout Management

Best practices for layout:
- Use lipgloss's `Height()` and `Width()` methods
- Avoid hard-coded dimensions
- Make layouts responsive to window size
- Handle borders and padding properly

## 6. Terminal Recovery

Handle panics gracefully:
- Implement panic recovery in commands
- Provide terminal reset functionality
- Use `tea.WithAltScreen()` for better terminal management
- Consider implementing a recovery mechanism

## 7. Testing

Use `teatest` for end-to-end testing:
- Test user interactions
- Verify program state
- Check output content
- Use golden files for regression testing

## 8. Documentation and Demos

Use VHS for:
- Recording demos
- Creating screenshots
- Documenting features
- Generating animated GIFs

## Implementation Priority

1. Event Loop Optimization
2. Layout Management
3. Terminal Recovery
4. Testing Infrastructure
5. Debugging Tools
6. Live Reload
7. Documentation
